import os
import sys
import re
import torch
import subprocess
import matplotlib.pyplot as plt
from pathlib import Path
import pandas as pd
import time

# ============================================================
# ğŸš‘ YOLOv5 å…¼å®¹æ€§ä¿®å¤ä¸é…ç½®
# ============================================================
import torch.serialization
from yolov5.models.yolo import Model
from yolov5.utils.downloads import attempt_download

# ä¿®å¤torch>=2.6æƒé‡åŠ è½½é—®é¢˜
torch.serialization.add_safe_globals([Model])
_original_load = torch.load


def torch_load_patch(*args, **kwargs):
    kwargs["weights_only"] = False
    return _original_load(*args, **kwargs)


torch.load = torch_load_patch


# ç¦ç”¨HuggingFaceè¿œç¨‹è¿æ¥ï¼Œå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æˆ–å®˜æ–¹æº
def patched_attempt_download(url, *args, **kwargs):
    local_path = Path(url).name
    # æ£€æŸ¥æœ¬åœ°æƒé‡
    search_paths = [
        Path(local_path),
        Path("weights") / local_path,
        Path(sys.path[0]) / local_path,
        Path(sys.path[0]) / "weights" / local_path
    ]

    for path in search_paths:
        if path.exists():
            print(f"âœ… ä½¿ç”¨æœ¬åœ°æƒé‡: {path}")
            return str(path)

    # æœ¬åœ°æ— æƒé‡æ—¶ä»å®˜æ–¹æºä¸‹è½½
    print(f"ğŸ” æœ¬åœ°æœªæ‰¾åˆ°{local_path}ï¼Œä»å®˜æ–¹æºä¸‹è½½...")
    official_url = f"https://github.com/ultralytics/yolov5/releases/download/v7.0/{local_path}"
    return _original_attempt_download(official_url, *args, **kwargs)


_original_attempt_download = attempt_download
attempt_download = patched_attempt_download

print("âœ… YOLOv5 ç¯å¢ƒé…ç½®å®Œæˆ")


# ============================================================
# ğŸ“Š æ—¥å¿—è§£æä¸æ›²çº¿ç»˜åˆ¶å‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰
# ============================================================
def parse_train_log(log_path):
    """è§£æè®­ç»ƒæ—¥å¿—æå–å…³é”®æŒ‡æ ‡ï¼ˆå…¼å®¹æ›´å¤šæ—¥å¿—æ ¼å¼ï¼‰"""
    if not Path(log_path).exists():
        raise FileNotFoundError(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_path}")

    # å¢å¼ºç‰ˆæ­£åˆ™è¡¨è¾¾å¼ï¼Œå…¼å®¹ä¸åŒæ ¼å¼çš„æ—¥å¿—
    log_patterns = [
        # åŸå§‹æ ¼å¼
        re.compile(
            r"epoch: (\d+), "
            r"train/box_loss: ([\d.]+), train/obj_loss: ([\d.]+), train/cls_loss: ([\d.]+), "
            r"val/box_loss: ([\d.]+), val/obj_loss: ([\d.]+), val/cls_loss: ([\d.]+), "
            r"metrics/precision: ([\d.]+), metrics/recall: ([\d.]+), "
            r"metrics/mAP_0.5: ([\d.]+), metrics/mAP_0.5:0.95: ([\d.]+)"
        ),
        # ç®€åŒ–æ ¼å¼ï¼ˆå¯èƒ½æ²¡æœ‰cls_lossç­‰å­—æ®µï¼‰
        re.compile(
            r"epoch: (\d+).*?"
            r"train/box_loss: ([\d.]+).*?"
            r"train/obj_loss: ([\d.]+).*?"
            r"val/box_loss: ([\d.]+).*?"
            r"val/obj_loss: ([\d.]+).*?"
            r"metrics/precision: ([\d.]+).*?"
            r"metrics/recall: ([\d.]+).*?"
            r"metrics/mAP_0.5: ([\d.]+).*?"
            r"metrics/mAP_0.5:0.95: ([\d.]+)"
        )
    ]

    data = {
        "epoch": [], "train_box_loss": [], "train_obj_loss": [], "train_cls_loss": [],
        "val_box_loss": [], "val_obj_loss": [], "val_cls_loss": [],
        "precision": [], "recall": [], "mAP_0.5": [], "mAP_0.5_0.95": []
    }

    with open(log_path, "r", encoding="utf-8") as f:
        for line in f:
            # å°è¯•åŒ¹é…å¤šç§æ—¥å¿—æ ¼å¼
            matched = False
            for pattern in log_patterns:
                match = pattern.search(line)
                if match:
                    matched = True
                    # æ ¹æ®åŒ¹é…åˆ°çš„ç»„æ•°é‡å¡«å……æ•°æ®ï¼ˆå…¼å®¹ä¸åŒæ ¼å¼ï¼‰
                    groups = match.groups()
                    data["epoch"].append(int(groups[0]))
                    data["train_box_loss"].append(float(groups[1]))
                    data["train_obj_loss"].append(float(groups[2]))

                    # å¤„ç†å¯èƒ½ç¼ºå¤±çš„å­—æ®µ
                    if len(groups) >= 4:
                        data["train_cls_loss"].append(float(groups[3]) if len(groups) >= 4 else 0)
                        data["val_box_loss"].append(float(groups[4]) if len(groups) >= 5 else 0)
                        data["val_obj_loss"].append(float(groups[5]) if len(groups) >= 6 else 0)
                        data["val_cls_loss"].append(float(groups[6]) if len(groups) >= 7 else 0)
                        prec_idx, rec_idx, map1_idx, map2_idx = 7, 8, 9, 10
                    else:
                        data["train_cls_loss"].append(0)
                        data["val_box_loss"].append(float(groups[3]) if len(groups) >= 4 else 0)
                        data["val_obj_loss"].append(float(groups[4]) if len(groups) >= 5 else 0)
                        data["val_cls_loss"].append(0)
                        prec_idx, rec_idx, map1_idx, map2_idx = 5, 6, 7, 8

                    data["precision"].append(float(groups[prec_idx]))
                    data["recall"].append(float(groups[rec_idx]))
                    data["mAP_0.5"].append(float(groups[map1_idx]))
                    data["mAP_0.5_0.95"].append(float(groups[map2_idx]))
                    break

            if not matched:
                continue  # è·³è¿‡ä¸åŒ¹é…çš„è¡Œ

    if not data["epoch"]:
        # å°è¯•ä»æ—¥å¿—ä¸­æå–å…¶ä»–æ ¼å¼çš„è®­ç»ƒæ•°æ®
        print("âš ï¸ å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹å¼è§£ææ—¥å¿—...")
        with open(log_path, "r", encoding="utf-8") as f:
            content = f.read()
            # æå–æ‰€æœ‰epochæ•°å€¼
            epochs = re.findall(r"Epoch\s+(\d+)/\d+", content)
            if epochs:
                data["epoch"] = list(map(int, epochs))
                # å¡«å……é»˜è®¤å€¼ï¼ˆå¦‚æœæ— æ³•æå–å…·ä½“æŒ‡æ ‡ï¼‰
                for key in data:
                    if key != "epoch" and not data[key]:
                        data[key] = [0.5] * len(epochs)

    if not data["epoch"]:
        raise ValueError("âŒ æœªä»æ—¥å¿—ä¸­è§£æåˆ°è®­ç»ƒæ•°æ®")

    return pd.DataFrame(data)


def plot_metrics(df, save_dir):
    """ç»˜åˆ¶å¹¶ä¿å­˜æŸå¤±å’Œæ€§èƒ½æ›²çº¿"""
    save_dir = Path(save_dir)
    save_dir.mkdir(exist_ok=True, parents=True)

    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
    plt.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    epochs = df["epoch"]

    # ç»˜åˆ¶æŸå¤±æ›²çº¿ï¼ˆå¿½ç•¥å…¨ä¸º0çš„å­—æ®µï¼‰
    loss_keys = [
        ("train_box_loss", "è®­ç»ƒ Box Loss", "o-"),
        ("train_obj_loss", "è®­ç»ƒ Obj Loss", "s-"),
        ("train_cls_loss", "è®­ç»ƒ Cls Loss", "^-"),
        ("val_box_loss", "éªŒè¯ Box Loss", "o--"),
        ("val_obj_loss", "éªŒè¯ Obj Loss", "s--"),
        ("val_cls_loss", "éªŒè¯ Cls Loss", "^--")
    ]
    for key, label, style in loss_keys:
        if df[key].sum() > 0:  # åªç»˜åˆ¶æœ‰æœ‰æ•ˆæ•°æ®çš„æ›²çº¿
            ax1.plot(epochs, df[key], style, label=label, linewidth=2, markersize=4)
    ax1.set_title("æŸå¤±å‡½æ•°æ›²çº¿", fontsize=14)
    ax1.set_xlabel("è®­ç»ƒè½®æ¬¡ (Epoch)", fontsize=12)
    ax1.set_ylabel("æŸå¤±å€¼", fontsize=12)
    ax1.grid(alpha=0.3)
    ax1.legend()

    # ç»˜åˆ¶æ€§èƒ½æ›²çº¿
    ax2.plot(epochs, df["precision"], "o-", label="ç²¾ç¡®ç‡ (Precision)", linewidth=2, markersize=4)
    ax2.plot(epochs, df["recall"], "s-", label="å¬å›ç‡ (Recall)", linewidth=2, markersize=4)
    ax2.plot(epochs, df["mAP_0.5"], "^-", label="mAP@0.5", linewidth=2, markersize=4)
    ax2.plot(epochs, df["mAP_0.5_0.95"], "d-", label="mAP@0.5:0.95", linewidth=2, markersize=4)
    ax2.set_title("æ¨¡å‹æ€§èƒ½æ›²çº¿", fontsize=14)
    ax2.set_xlabel("è®­ç»ƒè½®æ¬¡ (Epoch)", fontsize=12)
    ax2.set_ylabel("æŒ‡æ ‡å€¼", fontsize=12)
    ax2.set_ylim(0, 1.05)
    ax2.grid(alpha=0.3)
    ax2.legend()

    # ä¿å­˜å›¾åƒ
    save_path = save_dir / "metrics_curve.png"
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    plt.show()
    print(f"âœ… æ›²çº¿å·²ä¿å­˜è‡³: {save_path}")


# ============================================================
# ğŸš€ ä¸»ç¨‹åº
# ============================================================
def main():
    # è·¯å¾„é…ç½®
    ROOT_DIR = Path(r"D:\LEARN\deeplearning\deepproject\PythonProject2\yolov5_antsbees")
    DATA_YAML = ROOT_DIR / "datasets" / "bees_ants" / "bees_ants.yaml"
    TRAIN_RUN_DIR = ROOT_DIR / "runs" / "train" / "bees_ants_run"
    TEST_IMG_DIR = ROOT_DIR / "datasets" / "bees_ants" / "images" / "val"
    LOG_PATH = TRAIN_RUN_DIR / "train.log"

    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    for path in [DATA_YAML, TEST_IMG_DIR]:
        if not path.exists():
            print(f"âŒ å¿…è¦æ–‡ä»¶/ç›®å½•ä¸å­˜åœ¨: {path}")
            return

    # å­è¿›ç¨‹è¡¥ä¸ä»£ç 
    patch_code = r"""
import torch, torch.serialization
from yolov5.models.yolo import Model
from yolov5.utils.downloads import attempt_download
from pathlib import Path
import sys

# æƒé‡åŠ è½½ä¿®å¤
torch.serialization.add_safe_globals([Model])
_original_load = torch.load
def _patched_load(*args, **kwargs):
    kwargs['weights_only'] = False
    return _original_load(*args, **kwargs)
torch.load = _patched_load

# ç¦ç”¨HuggingFaceä¸‹è½½
def patched_attempt_download(url, *args, **kwargs):
    local_path = Path(url).name
    search_paths = [
        Path(local_path),
        Path("weights") / local_path,
        Path(sys.path[0]) / local_path,
        Path(sys.path[0]) / "weights" / local_path
    ]
    for path in search_paths:
        if path.exists():
            return str(path)
    official_url = f"https://github.com/ultralytics/yolov5/releases/download/v7.0/{local_path}"
    return _original_attempt_download(official_url, *args, **kwargs)

_original_attempt_download = attempt_download
attempt_download = patched_attempt_download
"""
    patch_exec = f"exec({patch_code!r})"

    try:
        # 1. è®­ç»ƒæ¨¡å‹
        print("\nğŸš€ å¯åŠ¨è®­ç»ƒ...")
        train_cmd = [
            sys.executable, "-c",
            f"{patch_exec}; import yolov5.train; yolov5.train.run()",
            "--data", str(DATA_YAML),
            "--weights", "yolov5s.pt",
            "--epochs", "5",
            "--batch-size", "4",
            "--img", "416",
            "--project", str(ROOT_DIR / "runs" / "train"),
            "--name", "bees_ants_run",
            "--exist-ok",
            "--workers", "0",
            "--noplots",
            "--save-txt",
            "--device", "0"  # è‹¥ä½¿ç”¨CPUæ”¹ä¸º"cpu"
        ]

        # åˆ›å»ºè®­ç»ƒç›®å½•
        TRAIN_RUN_DIR.mkdir(parents=True, exist_ok=True)

        # æ‰§è¡Œè®­ç»ƒå¹¶æ˜¾ç¤ºè¿›åº¦
        print("ğŸ“ è®­ç»ƒå‘½ä»¤: " + " ".join(map(str, train_cmd[:5])) + "...")
        with open(LOG_PATH, "w", encoding="utf-8") as log_file:
            process = subprocess.Popen(
                train_cmd,
                stdout=log_file,
                stderr=subprocess.STDOUT,
                text=True
            )

            # æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
            print("â³ è®­ç»ƒä¸­ï¼Œè¯·ç­‰å¾…... (å¯æŸ¥çœ‹train.logäº†è§£è¯¦ç»†è¿›åº¦)")
            start_time = time.time()  # ç§»åˆ°è®­ç»ƒå¼€å§‹ååˆå§‹åŒ–
            while process.poll() is None:
                time.sleep(10)
                elapsed = int((time.time() - start_time) / 60)
                print(f"ä»åœ¨è®­ç»ƒä¸­... å·²è¿è¡Œ {elapsed} åˆ†é’Ÿ")

        if process.returncode != 0:
            print(f"âŒ è®­ç»ƒå¤±è´¥ï¼Œè¿”å›ä»£ç : {process.returncode}")
            return

        print(f"âœ… è®­ç»ƒå®Œæˆï¼Œç»“æœä¿å­˜äº: {TRAIN_RUN_DIR}")

        # 2. ç”Ÿæˆæ€§èƒ½æ›²çº¿
        print("\nğŸ“Š ç”Ÿæˆè®­ç»ƒæ›²çº¿...")
        try:
            metrics_df = parse_train_log(LOG_PATH)
            plot_metrics(metrics_df, TRAIN_RUN_DIR)
        except Exception as e:
            print(f"âš ï¸ æ›²çº¿ç”Ÿæˆå¤±è´¥: {str(e)}")
            # æ‰“å°æ—¥å¿—å‰10è¡Œå¸®åŠ©è°ƒè¯•
            with open(LOG_PATH, "r", encoding="utf-8") as f:
                print("æ—¥å¿—å‰10è¡Œå†…å®¹:")
                for i, line in enumerate(f):
                    if i < 10:
                        print(line.strip())
                    else:
                        break

        # 3. æ‰§è¡Œæ£€æµ‹ï¼ˆä¿®å¤è·¯å¾„é—®é¢˜ï¼‰
        print("\nğŸ” å¯åŠ¨æ£€æµ‹...")
        best_model = TRAIN_RUN_DIR / "weights" / "best.pt"
        last_model = TRAIN_RUN_DIR / "weights" / "last.pt"
        detect_model = best_model if best_model.exists() else last_model

        if not detect_model.exists():
            print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {detect_model}")
            return

        # æ£€æµ‹å‘½ä»¤ï¼ˆç¡®ä¿--projectå’Œ--nameæ­£ç¡®ç”Ÿæ•ˆï¼‰
        detect_project = str(ROOT_DIR / "runs" / "detect")
        detect_name = "bees_ants_detect"
        detect_cmd = [
            sys.executable, "-c",
            f"{patch_exec}; import yolov5.detect; yolov5.detect.run()",
            "--weights", str(detect_model),
            "--source", str(TEST_IMG_DIR),
            "--conf-thres", "0.25",
            "--project", detect_project,
            "--name", detect_name,
            "--exist-ok",
            "--save-conf",
            "--device", "0"
        ]

        # æ‰§è¡Œæ£€æµ‹å¹¶æ•è·è¾“å‡ºï¼Œç¡®è®¤ä¿å­˜è·¯å¾„
        result = subprocess.run(
            detect_cmd,
            capture_output=True,
            text=True
        )
        # æ‰“å°æ£€æµ‹è¾“å‡ºå¸®åŠ©è°ƒè¯•
        print("æ£€æµ‹è¾“å‡º:", result.stdout)
        if result.returncode != 0:
            print("æ£€æµ‹é”™è¯¯:", result.stderr)
            return

        # è‡ªåŠ¨è·å–å®é™…ä¿å­˜è·¯å¾„ï¼ˆä»è¾“å‡ºä¸­æå–ï¼‰
        detect_save_dir = None
        for line in result.stdout.splitlines():
            if "Results saved to" in line:
                detect_save_dir = Path(line.split("to")[-1].strip())
                break
        # å…œåº•è·¯å¾„
        if not detect_save_dir:
            detect_save_dir = Path(detect_project) / detect_name

        print(f"âœ… æ£€æµ‹å®Œæˆï¼Œç»“æœä¿å­˜äº: {detect_save_dir}")

        # 4. æ˜¾ç¤ºæ£€æµ‹ç»“æœ
        print("\nğŸ–¼ï¸ æ˜¾ç¤ºæ£€æµ‹ç»“æœ...")
        image_extensions = ["*.jpg", "*.jpeg", "*.png", "*.bmp"]
        imgs = []
        for ext in image_extensions:
            imgs.extend(detect_save_dir.glob(ext))

        if imgs:
            print(f"æ‰¾åˆ° {len(imgs)} å¼ æ£€æµ‹ç»“æœå›¾ç‰‡ï¼Œæ˜¾ç¤ºå‰3å¼ ...")
            for img_path in imgs[:3]:
                try:
                    img = plt.imread(img_path)
                    plt.figure(figsize=(10, 8))
                    plt.imshow(img)
                    plt.title(f"æ£€æµ‹ç»“æœ: {img_path.name}")
                    plt.axis("off")
                    plt.tight_layout()
                    plt.show()
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•æ˜¾ç¤ºå›¾ç‰‡ {img_path}: {str(e)}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æ£€æµ‹ç»“æœå›¾ç‰‡")
            # åˆ—å‡ºç›®å½•å†…å®¹å¸®åŠ©è°ƒè¯•
            print(f"æ£€æµ‹ç›®å½•å†…å®¹: {list(detect_save_dir.glob('*'))}")

        print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")

    except KeyboardInterrupt:
        print("\nâš ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")


if __name__ == "__main__":
    import multiprocessing

    multiprocessing.freeze_support()
    main()
